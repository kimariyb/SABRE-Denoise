accelerator: gpu
batch_size: 32
early_stopping_patience: 20
inference_batch_size: 32
load_model: null
log_dir: ./logs
loss_type: mae
lr: 0.001
lr_factor: 0.8
lr_min: 1.0e-06
lr_patience: 5
lr_warmup_steps: 0
num_epochs: 50
num_nodes: 1
num_workers: 8
precision: 32
reload: 1
save_interval: 1
seed: 42
splits: null
task: train
test_root: ./test/
train_root: ./data/
train_size: 0.9
val_size: 0.1
weight_decay: 0.0001
